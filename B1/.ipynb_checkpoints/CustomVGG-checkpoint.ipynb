{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELEC0134 - Applied Machine Learning Systems Assignment 2019/2020\n",
    "## Task B1: Face Shape Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to detect 5 types of face shapes from the *cartoon_set* dataset:\n",
    "1. Setup data generator to load images dataset using Keras Image Preprocessing API\n",
    "2. Build an VGG-16 CNN architecture\n",
    "3. Fit the CNN model to the training data\n",
    "4. Test the performances of the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load labels.csv and convert to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  file_name  face_shape\n",
      "0     0.png           4\n",
      "1     1.png           4\n",
      "2     2.png           3\n",
      "3     3.png           0\n",
      "4     4.png           2\n",
      "  file_name  face_shape\n",
      "0     0.png           5\n",
      "1     1.png           5\n",
      "2     2.png           4\n",
      "3     3.png           1\n",
      "4     4.png           3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\env_dlib\\lib\\site-packages\\pandas\\core\\indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# Modified the directory\n",
    "os.chdir('..')\n",
    "AMLS_dir = os.path.abspath(os.curdir)\n",
    "basedir = os.path.join(AMLS_dir,'Datasets')\n",
    "cartoon_dir = os.path.join(basedir,'cartoon_set')\n",
    "images_dir = os.path.join(cartoon_dir,'img')\n",
    "labels_path = os.path.join(cartoon_dir,'labels.csv')\n",
    "\n",
    "# Converting csv into dataframe using read_csv(label_path)\n",
    "cartoon_df = pd.read_csv(os.path.normcase(labels_path), sep='\\t', engine='python')\n",
    "df = cartoon_df[['file_name', 'face_shape']]\n",
    "print(df.head())\n",
    "\n",
    "# Convert the face shape column to class 1-5\n",
    "df.loc[:,'face_shape'] += 1\n",
    "print(df.head())\n",
    "\n",
    "# Convert face shape column type from int64 to str for data generator\n",
    "df = df.applymap(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Setup data generators to draws from train, test and validation dataframe\n",
    "1. Convolution Neural Networks fed by batches of images to train, therefore need to convert from (size1, size2, channels) to (samples, size1, size2, channels).\n",
    "2. Split the dataframe into test, train and validation set.\n",
    "3. Use Keras Image Processing API (flow_from_dataframe) to load the images dataset according to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4900 validated image filenames belonging to 5 classes.\n",
      "Found 2100 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Import data generator API \n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Setup data generator for train and validation dataset generator\n",
    "train_df, test_df = train_test_split(df, train_size=0.7, random_state=42)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   validation_split=0.3)                     \n",
    "\n",
    "# Generating training and validation dataset for VGGNet CNN\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                                    directory=images_dir,\n",
    "                                                    x_col=\"file_name\",\n",
    "                                                    y_col=\"face_shape\",\n",
    "                                                    target_size=(32, 32),\n",
    "                                                    batch_size=32,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    subset='training')\n",
    "valid_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                                    directory=images_dir,\n",
    "                                                    x_col=\"file_name\",\n",
    "                                                    y_col=\"face_shape\",\n",
    "                                                    target_size=(32, 32),\n",
    "                                                    batch_size=32,\n",
    "                                                    shuffle=True, \n",
    "                                                    class_mode='categorical',\n",
    "                                                    subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using EarlyStopping and ModelCheckpoint Keras API callback to save the weights\n",
    "Too many training epochs will lead to overfitting the training dataset whereas too few will result underfitting. Therefore, it is better to monitor the performance of the model during training and call EarlyStopping when overfitting occurs and save the weights using ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use early stopping to terminate training epochs through callbacks\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Seek a mininum for validation loss and display the stopped epochs using verbose and adding delays\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "# Save best model using checkpoint\n",
    "B1_dir = os.path.join(AMLS_dir, 'B1')\n",
    "model_path = os.path.join(B1_dir, 'VGGNet.h5')\n",
    "mcp = ModelCheckpoint(os.path.normcase(model_path), monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "# Define callback function in a list\n",
    "callback_list = [es, mcp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Build the neural network using VGG-16 architecture\n",
    "1. Build the sequential model and add convolutional and max pooling layers to it.\n",
    "2. Add dropout layer at fully connected layer\n",
    "3. Add softmax layer at the end\n",
    "4. Compile the model and use ADAM (Adaptive learning rate optimization algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 131,557\n",
      "Trainable params: 131,077\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Import network libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "\n",
    "# Number of output classes\n",
    "num_class = 5\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add 1st convolution block\n",
    "model.add(Conv2D(filters=16, input_shape=train_generator.image_shape, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"))\n",
    "\n",
    "# Add 2nd convolution block\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"))\n",
    "\n",
    "# Add 3rd convolution block\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"))\n",
    "\n",
    "# Add 4th convolution block\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "# Output Layer (5 clases for face shapes)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=64,activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=num_class, activation=\"softmax\"))\n",
    "\n",
    "# Display summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Compile the model using ADAM (Adaptive learning rate optimization)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Fit the VGG-16 CNN to training and validation data\n",
    "Access model training history using history callback to record training metrics for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "32\n",
      "Epoch 1/30\n",
      "76/76 [==============================] - 219s 3s/step - loss: 1.6373 - accuracy: 0.2380 - val_loss: 1.8182 - val_accuracy: 0.2114\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.81821, saving model to d:\\ucl\\4th year\\applied machine learning system\\part 1\\assignment\\amls_assignment\\b1\\vggnet.h5\n",
      "Epoch 2/30\n",
      "76/76 [==============================] - 92s 1s/step - loss: 1.4419 - accuracy: 0.3182 - val_loss: 2.2628 - val_accuracy: 0.2058\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.81821\n",
      "Epoch 3/30\n",
      "76/76 [==============================] - 72s 954ms/step - loss: 1.3221 - accuracy: 0.3654 - val_loss: 2.3810 - val_accuracy: 0.1940\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.81821\n",
      "Epoch 4/30\n",
      "76/76 [==============================] - 92s 1s/step - loss: 1.2509 - accuracy: 0.4022 - val_loss: 1.8576 - val_accuracy: 0.1960\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.81821\n",
      "Epoch 5/30\n",
      "18/76 [======>.......................] - ETA: 27s - loss: 1.1836 - accuracy: 0.4531"
     ]
    }
   ],
   "source": [
    "# Set steps per epoch for callback \n",
    "STEP_SIZE_TRAIN = train_generator.samples//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.samples//valid_generator.batch_size\n",
    "print(STEP_SIZE_TRAIN)\n",
    "print(STEP_SIZE_VALID)\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                              epochs=30,\n",
    "                              callbacks=callback_list,\n",
    "                              validation_data=valid_generator,\n",
    "                              validation_steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Performances of CNN\n",
    "1. Plot the learning curve for model validation to select the optimum hyperparameters\n",
    "2. Evaluating model performances using standard metrics e.g confusion matrix, accurancy score, ROC curve and etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy score versus epochs\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss score versus epochs\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "# Evaluate the model with validation dataset\n",
    "eval_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                                    directory=images_dir,\n",
    "                                                    x_col=\"file_name\",\n",
    "                                                    y_col=\"face_shape\",\n",
    "                                                    target_size=(32, 32),\n",
    "                                                    batch_size=1,\n",
    "                                                    shuffle=True, \n",
    "                                                    class_mode='categorical',\n",
    "                                                    subset='validation')\n",
    "eval_model = model.evaluate_generator(generator=eval_generator, steps=STEP_SIZE_VALID, verbose=1)\n",
    "print('Training '+ str(model.metrics_names[0]) + ': '  + str(eval_model[0]))\n",
    "print('Training '+ str(model.metrics_names[1]) + ': '  + str(eval_model[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Fit the model to the test dataset by loading the model \n",
    "saved_model = load_model(model_path)\n",
    "\n",
    "# Generate test dataset from dataframe\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=test_df,\n",
    "                                                    directory=images_dir,\n",
    "                                                    x_col=\"file_name\",\n",
    "                                                    y_col=\"face_shape\",\n",
    "                                                    target_size=(32, 32),\n",
    "                                                    batch_size=1,\n",
    "                                                    shuffle=False,\n",
    "                                                    class_mode='categorical')\n",
    "STEP_SIZE_TEST = test_generator.samples//test_generator.batch_size\n",
    "test_generator.reset()\n",
    "pred = saved_model.predict_generator(test_generator, steps=STEP_SIZE_TEST, verbose=1)\n",
    "\n",
    "# Determine the maximum activation value at the output layers for each sample\n",
    "pred_class = np.argmax(pred, axis=1)   # axis = 1 give max value along each row\n",
    "\n",
    "# True labels of test dataset\n",
    "true_class = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_cm(true_label, pred_label):\n",
    "    # Plot non-normalized and normalize confusian matrix\n",
    "    class_names = ['Face Shape 1', 'Face Shape 2', 'Face Shape 3', 'Face Shape 4', 'Face Shape 5']\n",
    "    cm = confusion_matrix(true_label, pred_label)\n",
    "    norm_cm = normalize(cm)\n",
    "    \n",
    "    print('Confusion matrix')\n",
    "    print(cm)\n",
    "    print(accuracy_score(true_label, pred_label))\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,10))\n",
    "    im1 = ax1.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.colorbar(im1, fraction=0.05, pad=0.04, ax=ax1)\n",
    "    \n",
    "    ax1.set_xticks(np.arange(len(class_names)))\n",
    "    ax1.set_yticks(np.arange(len(class_names)))\n",
    "    ax1.set_xticklabels(class_names)\n",
    "    ax1.set_yticklabels(class_names)\n",
    "    ax1.set_title('Confusion matrix')\n",
    "    ax1.set_xlabel('Predicted labels')\n",
    "    ax1.set_ylabel('True labels')\n",
    "    \n",
    "    \n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax1.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    \n",
    "    print('Normalized confusion matrix')\n",
    "    print(norm_cm)\n",
    "    \n",
    "    im2 = ax2.imshow(norm_cm, interpolation=\"nearest\")\n",
    "    plt.colorbar(im2, fraction=0.05, pad=0.04, ax=ax2)\n",
    "    \n",
    "    ax2.set_xticks(np.arange(len(class_names)))\n",
    "    ax2.set_yticks(np.arange(len(class_names)))\n",
    "    ax2.set_xticklabels(class_names)\n",
    "    ax2.set_yticklabels(class_names)\n",
    "    ax2.set_title('Normalized confusion matrix')\n",
    "    ax2.set_xlabel('Predicted labels')\n",
    "    ax2.set_ylabel('True labels')\n",
    "    \n",
    "    \n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax2.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "#     fig, ax = plt.subplots()\n",
    "#     im = ax.imshow(cm, interpolation=\"nearest\")\n",
    "#     plt.colorbar(im)\n",
    "\n",
    "#     # Show all ticks and labels\n",
    "#     ax.set_xticks(np.arange(len(class_names)))\n",
    "#     ax.set_yticks(np.arange(len(class_names)))\n",
    "#     ax.set_xticklabels(class_names)\n",
    "#     ax.set_yticklabels(class_names)\n",
    "\n",
    "#     # Rotate the tick labels and set their alignment.\n",
    "#     plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "#              rotation_mode=\"anchor\")\n",
    "\n",
    "#     plt.title('Confusion matrix')\n",
    "#     plt.xlabel('Predicted labels')\n",
    "#     plt.ylabel('True labels')\n",
    "#     plt.show()\n",
    "    \n",
    "plot_cm(true_class, pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import extra dataset and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartoon_test_dir = os.path.join(basedir,'cartoon_set_test')\n",
    "images_test_dir = os.path.join(cartoon_test_dir,'img')\n",
    "labels_test_filename = os.path.join(cartoon_test_dir,'labels.csv')\n",
    "\n",
    "# Converting csv into dataframe using read_csv(label_path)\n",
    "cartoon_new_df = pd.read_csv(os.path.normcase(labels_test_filename), sep='\\t', engine='python')\n",
    "new_df = cartoon_new_df[['file_name', 'face_shape']]\n",
    "print(new_df.head())\n",
    "\n",
    "# Convert the face shape column to class 1-5\n",
    "new_df.loc[:,'face_shape'] += 1\n",
    "print(new_df.head())\n",
    "\n",
    "# Convert face shape column type from int64 to str for data generator\n",
    "new_df = new_df.applymap(str)\n",
    "\n",
    "# Generate extra test dataset from dataframe\n",
    "new_generator = test_datagen.flow_from_dataframe(dataframe=new_df,\n",
    "                                                directory=images_test_dir,\n",
    "                                                x_col=\"file_name\",\n",
    "                                                y_col=\"face_shape\",\n",
    "                                                target_size=(32, 32),\n",
    "                                                batch_size=1,\n",
    "                                                shuffle=False,\n",
    "                                                class_mode='categorical')\n",
    "STEP_SIZE_NEW = new_generator.samples//new_generator.batch_size\n",
    "new_generator.reset()\n",
    "new_pred = saved_model.predict_generator(new_generator, steps=STEP_SIZE_NEW, verbose=1)\n",
    "\n",
    "# Determine the maximum activation value at the output layers for each sample\n",
    "new_pred_class = np.argmax(new_pred, axis=1)   # axis = 1 give max value along each row\n",
    "\n",
    "# True labels of test dataset\n",
    "new_true_class = new_generator.classes\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_cm(new_true_class, new_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Map the predicted labels with unique id\n",
    "Map the predicted result with unique filenames to find out the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
