{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELEC0134 - Applied Machine Learning Systems Assignment 2019/2020\n",
    "## Task B1: Face Shape Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to detect 5 types of face shapes from the *cartoon_set* dataset:\n",
    "1. Setup data generator to load images dataset using Keras Image Preprocessing API\n",
    "2. Build an AlexNet CNN architecture\n",
    "3. Fit the CNN model to the training data\n",
    "4. Test the performances of the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load labels.csv and convert to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  file_name  face_shape\n",
      "0     0.png           4\n",
      "1     1.png           4\n",
      "2     2.png           3\n",
      "3     3.png           0\n",
      "4     4.png           2\n",
      "  file_name  face_shape\n",
      "0     0.png           5\n",
      "1     1.png           5\n",
      "2     2.png           4\n",
      "3     3.png           1\n",
      "4     4.png           3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# Modified the directory\n",
    "os.chdir('..')\n",
    "AMLS_dir = os.path.abspath(os.curdir)\n",
    "basedir = os.path.join(AMLS_dir,'Datasets')\n",
    "cartoon_dir = os.path.join(basedir,'cartoon_set')\n",
    "images_dir = os.path.join(cartoon_dir,'img')\n",
    "labels_path = os.path.join(cartoon_dir,'labels.csv')\n",
    "\n",
    "# Converting csv into dataframe using read_csv(label_path)\n",
    "cartoon_df = pd.read_csv(os.path.normcase(labels_path), sep='\\t', engine='python')\n",
    "df = cartoon_df[['file_name', 'face_shape']]\n",
    "print(df.head())\n",
    "\n",
    "# Convert the face shape column to class 1-5\n",
    "df.loc[:,'face_shape'] += 1\n",
    "print(df.head())\n",
    "\n",
    "# Convert face shape column type from int64 to str for data generator\n",
    "df = df.applymap(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Setup data generators to draws from train, test and validation dataframe\n",
    "1. Convolution Neural Networks fed by batches of images to train, therefore need to convert from (size1, size2, channels) to (samples, size1, size2, channels).\n",
    "2. Split the dataframe into test, train and validation set.\n",
    "3. Use Keras Image Processing API (flow_from_dataframe) to load the images dataset according to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5600 validated image filenames belonging to 5 classes.\n",
      "Found 1400 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Import data generator API \n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Setup data generator for test and train dataset generator\n",
    "train_df, test_df = train_test_split(df, train_size=0.7, random_state=42)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   validation_split=0.2)                     \n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generating training and validation dataset for AlexNet CNN\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                                    directory=images_dir,\n",
    "                                                    x_col=\"file_name\",\n",
    "                                                    y_col=\"face_shape\",\n",
    "                                                    target_size=(32, 32),\n",
    "                                                    batch_size=32,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    subset='training')\n",
    "valid_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                                    directory=images_dir,\n",
    "                                                    x_col=\"file_name\",\n",
    "                                                    y_col=\"face_shape\",\n",
    "                                                    target_size=(32, 32),\n",
    "                                                    batch_size=32,\n",
    "                                                    shuffle=True, \n",
    "                                                    class_mode='categorical',\n",
    "                                                    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.image_shape)\n",
    "print(train_generator.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using EarlyStopping and ModelCheckpoint Keras API callback to save the weights\n",
    "Too many training epochs will lead to overfitting the training dataset whereas too few will result underfitting. Therefore, it is better to monitor the performance of the model during training and call EarlyStopping when overfitting occurs and save the weights using ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use early stopping to terminate training epochs through callbacks\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Seek a mininum for validation loss and display the stopped epochs using verbose and adding delays\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "# Save best model using checkpoint\n",
    "B1_dir = os.path.join(AMLS_dir, 'B1')\n",
    "model_path = os.path.join(B1_dir, 'AlexNet.h5')\n",
    "mcp = ModelCheckpoint(os.path.normcase(model_path), monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "# Define callback function in a list\n",
    "callback_list = [es, mcp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Build the neural network using AlexNet architecture\n",
    "1. Build the sequential model and add convolutional and max pooling layers to it.\n",
    "2. Add batch normalization layer between each convolutional layer\n",
    "3. Add dropout layer between each fully connected layer\n",
    "4. Add softmax layer at the end\n",
    "5. Compile the model and use ADAM (Adaptive learning rate optimization algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 48)          17472     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 48)          192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 48)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 128)         153728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 192)         221376    \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 2, 192)         331968    \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 2, 2, 128)         221312    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 959,301\n",
      "Trainable params: 958,949\n",
      "Non-trainable params: 352\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Import network libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "\n",
    "# Number of output classes\n",
    "num_class = 5\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add 1st convolutional layer\n",
    "model.add(Conv2D(filters=48, input_shape=train_generator.image_shape, kernel_size=(11,11), strides=(4,4), \n",
    "                 padding=\"same\", activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding=\"same\"))\n",
    "\n",
    "# Add 2nd convolutional layer\n",
    "model.add(Conv2D(filters=128, kernel_size=(5,5), strides=(1,1), padding=\"same\", activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding=\"same\"))\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=192, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation = \"relu\"))\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=192, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation = \"relu\"))\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "# Passing to fully connected layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add 1st dense layer\n",
    "model.add(Dense(units=64, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add 2nd dense layer\n",
    "model.add(Dense(units=64, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output Layer (5 clases for face shapes)\n",
    "model.add(Dense(units=num_class, activation = \"relu\"))\n",
    "\n",
    "# Display summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Compile the model using ADAM (Adaptive learning rate optimization)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Fit the AlexNet CNN to training and validation data\n",
    "Access model training history using history callback to record training metrics for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n",
      "43\n",
      "Epoch 1/30\n",
      "175/175 [==============================] - 242s 1s/step - loss: nan - accuracy: 0.2018 - val_loss: nan - val_accuracy: 0.1984\n",
      "\n",
      "Epoch 00001: val_loss did not improve from inf\n",
      "Epoch 2/30\n",
      "  3/175 [..............................] - ETA: 7s - loss: nan - accuracy: 0.1979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py:1225: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py:992: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 25s 142ms/step - loss: nan - accuracy: 0.2018 - val_loss: nan - val_accuracy: 0.1937\n",
      "\n",
      "Epoch 00002: val_loss did not improve from inf\n",
      "Epoch 3/30\n",
      "175/175 [==============================] - 24s 138ms/step - loss: nan - accuracy: 0.2018 - val_loss: nan - val_accuracy: 0.1974\n",
      "\n",
      "Epoch 00003: val_loss did not improve from inf\n",
      "Epoch 4/30\n",
      "175/175 [==============================] - 25s 142ms/step - loss: nan - accuracy: 0.2018 - val_loss: nan - val_accuracy: 0.2025\n",
      "\n",
      "Epoch 00004: val_loss did not improve from inf\n",
      "Epoch 5/30\n",
      " 99/175 [===============>..............] - ETA: 9s - loss: nan - accuracy: 0.2049"
     ]
    }
   ],
   "source": [
    "# Set steps per epoch for callback \n",
    "STEP_SIZE_TRAIN = train_generator.samples//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.samples//valid_generator.batch_size\n",
    "print(STEP_SIZE_TRAIN)\n",
    "print(STEP_SIZE_VALID)\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                              epochs=30,\n",
    "                              callbacks=callback_list,\n",
    "                              validation_data=valid_generator,\n",
    "                              validation_steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Performances of CNN\n",
    "1. Plot the learning curve for model validation to select the optimum hyperparameters\n",
    "2. Evaluating model performances using standard metrics e.g confusion matrix, accurancy score and etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
