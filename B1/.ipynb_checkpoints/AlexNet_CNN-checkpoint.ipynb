{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELEC0134 - Applied Machine Learning Systems Assignment 2019/2020\n",
    "## Task B1: Face Shape Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to detect 5 types of face shapes from the *cartoon_set* dataset:\n",
    "1. Build an AlexNet CNN architecture\n",
    "2. Fit the CNN model to the training data\n",
    "3. Test the performances of the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "\n",
    "# Import network libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Build the neural network using AlexNet architecture\n",
    "1. Build the sequential model and add convolutional and max pooling layers to it.\n",
    "2. Add batch normalization layer between each convolutional layer\n",
    "3. Add dropout layer between each fully connected layer\n",
    "4. Add softmax layer at the end\n",
    "5. Compile the model and use ADAM (Adaptive learning rate optimization algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 55, 55, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 55, 55, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 23, 23, 256)       614656    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 23, 23, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 23, 23, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 384)         885120    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 9, 9, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 7, 7, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 5, 5, 256)         884992    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              4198400   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 5005      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 28,830,325\n",
      "Trainable params: 28,829,621\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n",
      "[<keras.layers.convolutional.Conv2D object at 0x000002228C012508>, <keras.layers.core.Activation object at 0x000002228C012F88>, <keras.layers.normalization.BatchNormalization object at 0x000002228C06F508>, <keras.layers.pooling.MaxPooling2D object at 0x000002228C06F7C8>, <keras.layers.convolutional.Conv2D object at 0x000002228C081208>, <keras.layers.core.Activation object at 0x000002228C0594C8>, <keras.layers.normalization.BatchNormalization object at 0x000002228C190CC8>, <keras.layers.pooling.MaxPooling2D object at 0x000002228C194F48>, <keras.layers.convolutional.Conv2D object at 0x000002228C1A4888>, <keras.layers.core.Activation object at 0x000002228C010748>, <keras.layers.convolutional.Conv2D object at 0x000002228C00A8C8>, <keras.layers.core.Activation object at 0x000002228C00E508>, <keras.layers.convolutional.Conv2D object at 0x000002228C005588>, <keras.layers.core.Activation object at 0x000002228C003688>, <keras.layers.pooling.MaxPooling2D object at 0x000002228C005048>, <keras.layers.core.Flatten object at 0x000002228BFFEC88>, <keras.layers.core.Dense object at 0x000002228BFFCE88>, <keras.layers.core.Activation object at 0x000002228BFFEA88>, <keras.layers.core.Dropout object at 0x000002228BFFCC88>, <keras.layers.core.Dense object at 0x000002228C257148>, <keras.layers.core.Activation object at 0x000002228C08B708>, <keras.layers.core.Dropout object at 0x000002228C31B648>, <keras.layers.core.Dense object at 0x000002228C320148>, <keras.layers.core.Activation object at 0x000002228C31B988>, <keras.layers.core.Dropout object at 0x000002228C36C448>, <keras.layers.core.Dense object at 0x000002228C36CF88>, <keras.layers.core.Activation object at 0x000002228C36C808>]\n"
     ]
    }
   ],
   "source": [
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add 1st convolutional layer\n",
    "model.add(Conv2D(filters=96, input_shape=(227,227,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# Add 2nd convolutional layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# Add 3rd convolutional layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Add 4th convolutional layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Add 5th convolutional layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# Passing to fully connected layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add 1st dense layer\n",
    "model.add(Dense(4096, input_shape=(256*6*6,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add 2nd dense layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add 3rd Dense Layer\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output Layer (5 clases for face shapes)\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Display summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Compile the model using ADAM (Adaptive learning rate optimization)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "print(len(model.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load labels.csv and convert to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  file_name  face_shape\n",
      "0     0.png           4\n",
      "1     1.png           4\n",
      "2     2.png           3\n",
      "3     3.png           0\n",
      "4     4.png           2\n",
      "  file_name  face_shape\n",
      "0     0.png           5\n",
      "1     1.png           5\n",
      "2     2.png           4\n",
      "3     3.png           1\n",
      "4     4.png           3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# Modified the directory\n",
    "os.chdir('..')\n",
    "AMLS_dir = os.path.abspath(os.curdir)\n",
    "basedir = os.path.join(AMLS_dir,'Datasets')\n",
    "cartoon_dir = os.path.join(basedir,'cartoon_set')\n",
    "images_dir = os.path.join(cartoon_dir,'img')\n",
    "labels_path = os.path.join(cartoon_dir,'labels.csv')\n",
    "\n",
    "# Converting csv into dataframe using read_csv(label_path)\n",
    "cartoon_df = pd.read_csv(os.path.normcase(labels_path), sep='\\t', engine='python')\n",
    "df = cartoon_df[['file_name', 'face_shape']]\n",
    "print(df.head())\n",
    "\n",
    "# Convert the face shape column to class 1-5\n",
    "df.loc[:,'face_shape'] += 1\n",
    "print(df.head())\n",
    "\n",
    "# Convert face shape column type from int64 to str for data generator\n",
    "df = df.applymap(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name     object\n",
      "face_shape    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "result = df.dtypes\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup data generators to draws from train, test and validation dataframe\n",
    "1. Convolution Neural Networks fed by batches of images to train, therefore need to convert from (size1, size2, channels) to (samples, size1, size2, channels). **Note that the input shape to AlexNet CNN is (227, 227)**\n",
    "2. Split the dataframe into test, train and validation set.\n",
    "3. Use Keras Image Processing API (flow_from_dataframe) to load the images dataset according to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5600 validated image filenames belonging to 5 classes.\n",
      "Found 1400 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, train_size=0.7, random_state=42)\n",
    "\n",
    "# Import data generator API \n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Setup data generator for test and train dataset generator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   validation_split=0.2)\n",
    "                                   \n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generating training and validation dataset for AlexNet CNN\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                                    directory=images_dir,\n",
    "                                                    x_col=\"file_name\",\n",
    "                                                    y_col=\"face_shape\",\n",
    "                                                    target_size=(227, 227),\n",
    "                                                    batch_size=32,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    subset='training')\n",
    "\n",
    "valid_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                                    directory=images_dir,\n",
    "                                                    x_col=\"file_name\",\n",
    "                                                    y_col=\"face_shape\",\n",
    "                                                    target_size=(227, 227),\n",
    "                                                    batch_size=32,\n",
    "                                                    shuffle=True, \n",
    "                                                    class_mode='categorical',\n",
    "                                                    subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using EarlyStopping and ModelCheckpoint Keras API callback to save the weights\n",
    "Too many training epochs will lead to overfitting the training dataset whereas too few will result underfitting. Therefore, it is better to monitor the performance of the model during training and call EarlyStopping when overfitting occurs and save the weights using ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use early stopping to terminate training epochs through callbacks\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Seek a mininum for validation loss and display the stopped epochs using verbose and adding delays\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "# Save best model using checkpoint\n",
    "B1_dir = os.path.join(AMLS_dir, 'B1')\n",
    "model_path = os.path.join(B1_dir, 'AlexNet.h5')\n",
    "mcp = ModelCheckpoint(os.path.normcase(model_path), monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "# Define callback function in a list\n",
    "callback_list = [es, mcp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Fit the AlexNet CNN to training and validation data\n",
    "Access model training history using history callback to record training metrics for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n",
      "43\n",
      "Epoch 1/30\n",
      " 71/175 [===========>..................] - ETA: 3:31 - loss: 1.9116 - accuracy: 0.1941"
     ]
    }
   ],
   "source": [
    "# Set steps per epoch for callback \n",
    "STEP_SIZE_TRAIN = train_generator.samples//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.samples//valid_generator.batch_size\n",
    "print(STEP_SIZE_TRAIN)\n",
    "print(STEP_SIZE_VALID)\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                              epochs=30,\n",
    "                              callbacks=callback_list,\n",
    "                              validation_data=valid_generator,\n",
    "                              validation_steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Performances of CNN\n",
    "1. Plot the learning curve for model validation to select the optimum hyperparameters\n",
    "2. Evaluating model performances using standard metrics e.g confusion matrix, accurancy score and etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
